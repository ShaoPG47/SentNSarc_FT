{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab03b0e3",
   "metadata": {},
   "source": [
    "# Data Loadin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5d7515",
   "metadata": {},
   "source": [
    "## Sentiment Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfe09b0",
   "metadata": {},
   "source": [
    "### TweetEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58d1a708",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penglishao/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63a75deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETA: 2:18:46\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "N_sent, N_sarc = 19494, 6235\n",
    "N = N_sent + N_sarc\n",
    "P = 3.09   # 换成你最新测到的吞吐（CPU 或 MPS）\n",
    "eta_seconds = N / P\n",
    "print(\"ETA:\", timedelta(seconds=int(eta_seconds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50140dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"/Users/penglishao/Desktop/DS5500/project\"   # 如果在别的路径运行，改成你的 project 根，例如 \"/Users/xxx/project\"\n",
    "TWEETEVAL_DIR = os.path.join(ROOT, \"data\", \"tweetEval\")\n",
    "\n",
    "SENTIMENT_DIR = os.path.join(TWEETEVAL_DIR, \"sentiment\")\n",
    "IRONY_DIR     = os.path.join(TWEETEVAL_DIR, \"irony\")\n",
    "\n",
    "# 输出目录\n",
    "OUT_DIR = os.path.join(ROOT, \"data\", \"processed\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f75828da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 2) 读取一个子任务（sentiment 或 irony）某个 split 的文本和标签 ======\n",
    "def load_split(task_dir, split):\n",
    "    \"\"\"\n",
    "    task_dir: e.g., data/tweetEval/sentiment  或  data/tweetEval/irony\n",
    "    split: \"train\" | \"val\" | \"test\"\n",
    "    returns: pd.DataFrame with columns [\"text\", \"label_id\"]\n",
    "    \"\"\"\n",
    "    text_fp  = os.path.join(task_dir, f\"{split}_text.txt\")\n",
    "    label_fp = os.path.join(task_dir, f\"{split}_labels.txt\")\n",
    "    # 读文本\n",
    "    with open(text_fp, \"r\", encoding=\"utf-8\") as f:\n",
    "        texts = [line.rstrip(\"\\n\") for line in f]\n",
    "    # 读标签\n",
    "    with open(label_fp, \"r\", encoding=\"utf-8\") as f:\n",
    "        labels = [int(line.strip()) for line in f]\n",
    "\n",
    "    if len(texts) != len(labels):\n",
    "        raise ValueError(f\"Text/label length mismatch in {task_dir}, {split}: {len(texts)} vs {len(labels)}\")\n",
    "    return pd.DataFrame({\"text\": texts, \"label_id\": labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdca7e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 3) 组装 sentiment_df ======\n",
    "# 你的需求：0=neg, 1=neu, 2=pos\n",
    "sentiment_label_map_id2name = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "\n",
    "dfs_sentiment = []\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    df = load_split(SENTIMENT_DIR, split)\n",
    "    # 保留原始 id，同时映射到我们需要的列名 \"sentiment\"\n",
    "    df[\"sentiment\"] = df[\"label_id\"].map({0:0, 1:1, 2:2})  # 显式映射，确保一致\n",
    "    df[\"sentiment_name\"] = df[\"label_id\"].map(sentiment_label_map_id2name)\n",
    "    df[\"split\"] = split\n",
    "    dfs_sentiment.append(df[[\"text\", \"sentiment\", \"sentiment_name\", \"split\"]])\n",
    "\n",
    "sentiment_df = pd.concat(dfs_sentiment, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bdfb229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_name</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"QT @user In the original draft of the 7th boo...</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Ben Smith / Smith (concussion) remains out of...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sorry bout the stream last night I crashed out...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chase Headley's RBI double in the 8th inning o...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@user Alciato: Bee will invest 150 million in ...</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment  \\\n",
       "0  \"QT @user In the original draft of the 7th boo...          2   \n",
       "1  \"Ben Smith / Smith (concussion) remains out of...          1   \n",
       "2  Sorry bout the stream last night I crashed out...          1   \n",
       "3  Chase Headley's RBI double in the 8th inning o...          1   \n",
       "4  @user Alciato: Bee will invest 150 million in ...          2   \n",
       "\n",
       "  sentiment_name  split  \n",
       "0       positive  train  \n",
       "1        neutral  train  \n",
       "2        neutral  train  \n",
       "3        neutral  train  \n",
       "4       positive  train  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4d5302b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 4) 组装 sarcasm_df（irony 子任务） ======\n",
    "# 你的需求：0=non-sarcastic, 1=sarcastic\n",
    "sarcasm_label_map_id2name = {0: \"non-sarcastic\", 1: \"sarcastic\"}\n",
    "\n",
    "dfs_sarcasm = []\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    df = load_split(IRONY_DIR, split)\n",
    "    df[\"sarcasm\"] = df[\"label_id\"].map({0:0, 1:1})\n",
    "    df[\"sarcasm_name\"] = df[\"label_id\"].map(sarcasm_label_map_id2name)\n",
    "    df[\"split\"] = split\n",
    "    dfs_sarcasm.append(df[[\"text\", \"sarcasm\", \"sarcasm_name\", \"split\"]])\n",
    "\n",
    "sarcasm_df = pd.concat(dfs_sarcasm, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8281821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>sarcasm_name</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seeing ppl walking w/ crutches makes me really...</td>\n",
       "      <td>1</td>\n",
       "      <td>sarcastic</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>look for the girl with the broken smile, ask h...</td>\n",
       "      <td>0</td>\n",
       "      <td>non-sarcastic</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Now I remember why I buy books online @user #s...</td>\n",
       "      <td>1</td>\n",
       "      <td>sarcastic</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@user @user So is he banded from wearing the c...</td>\n",
       "      <td>1</td>\n",
       "      <td>sarcastic</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just found out there are Etch A Sketch apps.  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>sarcastic</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sarcasm   sarcasm_name  \\\n",
       "0  seeing ppl walking w/ crutches makes me really...        1      sarcastic   \n",
       "1  look for the girl with the broken smile, ask h...        0  non-sarcastic   \n",
       "2  Now I remember why I buy books online @user #s...        1      sarcastic   \n",
       "3  @user @user So is he banded from wearing the c...        1      sarcastic   \n",
       "4  Just found out there are Etch A Sketch apps.  ...        1      sarcastic   \n",
       "\n",
       "   split  \n",
       "0  train  \n",
       "1  train  \n",
       "2  train  \n",
       "3  train  \n",
       "4  train  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarcasm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f85a183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment splits:\n",
      " split\n",
      "train    45615\n",
      "test     12284\n",
      "val       2000\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Sentiment label counts:\n",
      " sentiment_name\n",
      "neutral     27479\n",
      "positive    21043\n",
      "negative    11377\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Sarcasm splits:\n",
      " split\n",
      "train    2862\n",
      "val       955\n",
      "test      784\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Sarcasm label counts:\n",
      " sarcasm_name\n",
      "non-sarcastic    2389\n",
      "sarcastic        2212\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Examples (sentiment):\n",
      "                                                    text  sentiment  \\\n",
      "45192  @user @user BJP may be liking Rahul Gandhi now...          2   \n",
      "22309  The guy who let me borrow his Ohio State bag F...          2   \n",
      "33992  @user @user will NEVER but the sun Jo\\u002c ne...          0   \n",
      "\n",
      "      sentiment_name  split  \n",
      "45192       positive  train  \n",
      "22309       positive  train  \n",
      "33992       negative  train   \n",
      "\n",
      "Examples (sarcasm):\n",
      "                                                   text  sarcasm  \\\n",
      "3683  In Scotland ( the little country that's attach...        0   \n",
      "4412  A Puppet at the #PTI rally wanting to make #Na...        1   \n",
      "2584  It's such a joy to wake up sick again and not ...        1   \n",
      "\n",
      "       sarcasm_name  split  \n",
      "3683  non-sarcastic    val  \n",
      "4412      sarcastic   test  \n",
      "2584      sarcastic  train   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ====== 5) 简要检查 ======\n",
    "print(\"Sentiment splits:\\n\", sentiment_df[\"split\"].value_counts(), \"\\n\")\n",
    "print(\"Sentiment label counts:\\n\", sentiment_df[\"sentiment_name\"].value_counts(), \"\\n\")\n",
    "\n",
    "print(\"Sarcasm splits:\\n\", sarcasm_df[\"split\"].value_counts(), \"\\n\")\n",
    "print(\"Sarcasm label counts:\\n\", sarcasm_df[\"sarcasm_name\"].value_counts(), \"\\n\")\n",
    "\n",
    "print(\"Examples (sentiment):\")\n",
    "print(sentiment_df.sample(3, random_state=42), \"\\n\")\n",
    "print(\"Examples (sarcasm):\")\n",
    "print(sarcasm_df.sample(3, random_state=42), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76b1239a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to:\n",
      " /Users/penglishao/Desktop/DS5500/project/data/processed/sentiment_df.csv \n",
      " /Users/penglishao/Desktop/DS5500/project/data/processed/sarcasm_df.csv\n"
     ]
    }
   ],
   "source": [
    "# ====== 6) 保存文件 ======\n",
    "sentiment_csv  = os.path.join(OUT_DIR, \"sentiment_df.csv\")\n",
    "sarcasm_csv    = os.path.join(OUT_DIR, \"sarcasm_df.csv\")\n",
    "sentiment_parq = os.path.join(OUT_DIR, \"sentiment_df.parquet\")\n",
    "sarcasm_parq   = os.path.join(OUT_DIR, \"sarcasm_df.parquet\")\n",
    "\n",
    "sentiment_df.to_csv(sentiment_csv, index=False)\n",
    "sarcasm_df.to_csv(sarcasm_csv, index=False)\n",
    "try:\n",
    "    sentiment_df.to_parquet(sentiment_parq, index=False)\n",
    "    sarcasm_df.to_parquet(sarcasm_parq, index=False)\n",
    "except Exception as e:\n",
    "    print(\"Parquet save failed (ok to ignore if pyarrow not installed):\", e)\n",
    "\n",
    "print(\"Saved to:\\n\", sentiment_csv, \"\\n\", sarcasm_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575cc455",
   "metadata": {},
   "source": [
    "### Stanford Sentiment Treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350cb487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /Users/penglishao/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"YourToken\")\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5b51d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/penglishao/.cache/huggingface/datasets/SetFit___json/SetFit--sst5-4c07b9d5881ae209/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef981b5222c4adda0f86a881676586a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sst = load_dataset(\"SetFit/sst5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "422f4f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'label_text'],\n",
       "        num_rows: 8544\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'label_text'],\n",
       "        num_rows: 1101\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'label_text'],\n",
       "        num_rows: 2210\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ffe6a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) 读取标签名字（如果是 ClassLabel）\n",
    "label_names = None\n",
    "if \"label\" in sst[\"train\"].features and hasattr(sst[\"train\"].features[\"label\"], \"names\"):\n",
    "    label_names = sst[\"train\"].features[\"label\"].names  # e.g. ['very negative','negative','neutral','positive','very positive']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e3d7364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 5类 -> 3类的映射\n",
    "map_5to3_name = {\n",
    "    \"very negative\": \"negative\",\n",
    "    \"negative\": \"negative\",\n",
    "    \"neutral\": \"neutral\",\n",
    "    \"positive\": \"positive\",\n",
    "    \"very positive\": \"positive\",\n",
    "}\n",
    "sentiment_id_map = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "\n",
    "def split_name_for_te(s):  # 统一 split 命名：train/val/test\n",
    "    return {\"train\":\"train\", \"validation\":\"val\", \"test\":\"test\"}[s]\n",
    "\n",
    "def to_df(split):\n",
    "    # to pandas\n",
    "    df = sst[split].to_pandas()\n",
    "\n",
    "    # 自动识别文本列名\n",
    "    text_col = \"text\" if \"text\" in df.columns else (\"sentence\" if \"sentence\" in df.columns else None)\n",
    "    if text_col is None:\n",
    "        raise ValueError(f\"无法在 SetFit/sst5 的 {split} split 里找到文本列（期望 'text' 或 'sentence'）\")\n",
    "\n",
    "    # 取 label 原始名字\n",
    "    if \"label_text\" in df.columns:\n",
    "        label_5 = df[\"label_text\"].astype(str)\n",
    "    elif \"label\" in df.columns:\n",
    "        if label_names is None:\n",
    "            # 兜底：假设是 0..4 的整数，并按常见顺序映射\n",
    "            fallback = {0:\"very negative\", 1:\"negative\", 2:\"neutral\", 3:\"positive\", 4:\"very positive\"}\n",
    "            label_5 = df[\"label\"].map(fallback).astype(str)\n",
    "        else:\n",
    "            label_5 = df[\"label\"].map(lambda i: label_names[int(i)]).astype(str)\n",
    "    else:\n",
    "        raise ValueError(f\"未找到 label 列（期望 'label' 或 'label_text'） in {split}\")\n",
    "\n",
    "    # 5类 -> 3类（名字）\n",
    "    label_3_name = label_5.map(map_5to3_name)\n",
    "\n",
    "    # 名字 -> id（0/1/2）\n",
    "    label_3_id = label_3_name.map(sentiment_id_map).astype(int)\n",
    "\n",
    "    # 组织为统一结构\n",
    "    out = pd.DataFrame({\n",
    "        \"text\": df[text_col].astype(str),\n",
    "        \"sentiment_name\": label_3_name,\n",
    "        \"sentiment\": label_3_id,\n",
    "        \"split\": split_name_for_te(split),\n",
    "    })\n",
    "\n",
    "    # 基本清洗：去空白\n",
    "    out[\"text\"] = out[\"text\"].str.strip()\n",
    "    return out[[\"text\", \"sentiment\", \"sentiment_name\", \"split\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6d7b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  sentiment  \\\n",
      "0  a stirring , funny and finally transporting re...          2   \n",
      "1  apparently reassembled from the cutting-room f...          0   \n",
      "2  they presume their audience wo n't sit still f...          0   \n",
      "3  the entire movie is filled with deja vu moments .          1   \n",
      "4  this is a visually stunning rumination on love...          2   \n",
      "\n",
      "  sentiment_name  split  \n",
      "0       positive  train  \n",
      "1       negative  train  \n",
      "2       negative  train  \n",
      "3        neutral  train  \n",
      "4       positive  train  \n",
      "split\n",
      "train    8544\n",
      "test     2210\n",
      "val      1101\n",
      "Name: count, dtype: int64\n",
      "sentiment_name\n",
      "positive    4963\n",
      "negative    4650\n",
      "neutral     2242\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 4) 生成 sst5 的三分类 DataFrame\n",
    "sst5_sentiment_df = pd.concat(\n",
    "    [to_df(\"train\"), to_df(\"validation\"), to_df(\"test\")],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "print(sst5_sentiment_df.head())\n",
    "print(sst5_sentiment_df[\"split\"].value_counts())\n",
    "print(sst5_sentiment_df[\"sentiment_name\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afe61bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_name</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a stirring , funny and finally transporting re...</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apparently reassembled from the cutting-room f...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>they presume their audience wo n't sit still f...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the entire movie is filled with deja vu moments .</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this is a visually stunning rumination on love...</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment  \\\n",
       "0  a stirring , funny and finally transporting re...          2   \n",
       "1  apparently reassembled from the cutting-room f...          0   \n",
       "2  they presume their audience wo n't sit still f...          0   \n",
       "3  the entire movie is filled with deja vu moments .          1   \n",
       "4  this is a visually stunning rumination on love...          2   \n",
       "\n",
       "  sentiment_name  split  \n",
       "0       positive  train  \n",
       "1       negative  train  \n",
       "2       negative  train  \n",
       "3        neutral  train  \n",
       "4       positive  train  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sst5_sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b40fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) （可选）保存\n",
    "sst5_sentiment_df.to_csv(\"../data/processed/sentiment_sst5_mapped.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fda9ba",
   "metadata": {},
   "source": [
    "### MARC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "71a10090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d6b8bf3aa24fceb18d6c175fbad7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset amazon_reviews_multi (/Users/penglishao/.cache/huggingface/datasets/mteb___amazon_reviews_multi/en/1.0.0/61154b14772a2d73f3554caa8f5bd1fec4b65ec64f70bb93fa9fec6b038a4355)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e70c2ba12e4f434880f24a2f87383e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MARC_ds = load_dataset(\"mteb/amazon_reviews_multi\", \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3513c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) 1–5 星 -> 三分类 (0=neg,1=neu,2=pos)\n",
    "def stars_to_sentiment_id(stars: int) -> int:\n",
    "    if stars in (1, 2):\n",
    "        return 0\n",
    "    elif stars == 3:\n",
    "        return 1\n",
    "    elif stars in (4, 5):\n",
    "        return 2\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected stars value: {stars}\")\n",
    "\n",
    "sentiment_id_to_name = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "\n",
    "def norm_split(s): \n",
    "    return {\"train\": \"train\", \"validation\": \"val\", \"test\": \"test\"}[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "10b47751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 从 label / label_text 推断星级（1..5）\n",
    "def infer_stars(df: pd.DataFrame) -> pd.Series:\n",
    "    if \"label\" in df.columns:\n",
    "        lab = pd.to_numeric(df[\"label\"], errors=\"coerce\")\n",
    "        # 如果是 0..4 索引 → +1 变成 1..5\n",
    "        if lab.dropna().between(0, 4).all():\n",
    "            return (lab + 1).astype(int)\n",
    "        # 如果已经是 1..5，原样返回\n",
    "        if lab.dropna().between(1, 5).all():\n",
    "            return lab.astype(int)\n",
    "    if \"label_text\" in df.columns:\n",
    "        # 例如 \"1 star\" / \"5 stars\" / \"3\"\n",
    "        return df[\"label_text\"].astype(str).str.extract(r'(\\d)').astype(int)[0]\n",
    "    raise ValueError(f\"Cannot infer stars; columns present: {list(df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "417c2b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) 取文本列\n",
    "def get_text_col(df: pd.DataFrame) -> pd.Series:\n",
    "    if \"text\" in df.columns:\n",
    "        return df[\"text\"].astype(str)\n",
    "    # 兜底：找第一个字符串列\n",
    "    text_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "    if text_cols:\n",
    "        return df[text_cols[0]].astype(str)\n",
    "    raise ValueError(\"No text column found (expected 'text').\")\n",
    "\n",
    "def to_df(split):\n",
    "    hf = MARC_ds[split].to_pandas()\n",
    "    text = get_text_col(hf).str.strip()\n",
    "    stars = infer_stars(hf)\n",
    "    sent_id = stars.map(stars_to_sentiment_id).astype(int)\n",
    "    sent_name = sent_id.map(sentiment_id_to_name)\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"text\": text,\n",
    "        \"sentiment\": sent_id,              # 0=neg,1=neu,2=pos\n",
    "        \"sentiment_name\": sent_name,\n",
    "        \"split\": norm_split(split),\n",
    "    })\n",
    "    return out[[\"text\", \"sentiment\", \"sentiment_name\", \"split\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6efded39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split\n",
      "train    200000\n",
      "val        5000\n",
      "test       5000\n",
      "Name: count, dtype: int64\n",
      "sentiment_name\n",
      "negative    84000\n",
      "positive    84000\n",
      "neutral     42000\n",
      "Name: count, dtype: int64\n",
      "                                                     text  sentiment  \\\n",
      "131072    It is functional.\\n\\nVery good. I recommend it.          2   \n",
      "61816   Hurt my feet\\n\\nI don’t know why but I just di...          0   \n",
      "28020   Pic not what was sent\\n\\nWhat they show in the...          0   \n",
      "\n",
      "       sentiment_name  split  \n",
      "131072       positive  train  \n",
      "61816        negative  train  \n",
      "28020        negative  train  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5) 生成 DataFrame（MARC -> 三分类 sentiment）\n",
    "marc_sentiment_df = pd.concat(\n",
    "    [to_df(\"train\"), to_df(\"validation\"), to_df(\"test\")],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# 6) 简要检查\n",
    "print(marc_sentiment_df[\"split\"].value_counts())\n",
    "print(marc_sentiment_df[\"sentiment_name\"].value_counts())\n",
    "print(marc_sentiment_df.sample(3, random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "db49ccc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_name</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'll spend twice the amount of time boxing up ...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not use able\\n\\nthe cabinet dot were all detac...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The product is junk.\\n\\nI received my first or...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fucking waste of money\\n\\nThis product is a pi...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bubble\\n\\nwent through 3 in one day doesn't fi...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment  \\\n",
       "0  I'll spend twice the amount of time boxing up ...          0   \n",
       "1  Not use able\\n\\nthe cabinet dot were all detac...          0   \n",
       "2  The product is junk.\\n\\nI received my first or...          0   \n",
       "3  Fucking waste of money\\n\\nThis product is a pi...          0   \n",
       "4  bubble\\n\\nwent through 3 in one day doesn't fi...          0   \n",
       "\n",
       "  sentiment_name  split  \n",
       "0       negative  train  \n",
       "1       negative  train  \n",
       "2       negative  train  \n",
       "3       negative  train  \n",
       "4       negative  train  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marc_sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a83cc847",
   "metadata": {},
   "outputs": [],
   "source": [
    "marc_sentiment_df.to_csv(\"../data/processed/sentiment_marc_mapped.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fe7f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef2eb72c",
   "metadata": {},
   "source": [
    "## Sarcasm Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fc4b5c",
   "metadata": {},
   "source": [
    "### SARC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d001f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f18fe0c4",
   "metadata": {},
   "source": [
    "### SemEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8f89ca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"/Users/penglishao/Desktop/DS5500/project\"  # 改成你的项目根目录\n",
    "IN_DIR = os.path.join(BASE_DIR, \"data\", \"SemEval\")\n",
    "OUT_DIR = os.path.join(BASE_DIR, \"data\", \"processed\", \"sarcasm_data\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "FILES = [\n",
    "    \"SemEval2018-T3-train-taskA.txt\",\n",
    "    \"SemEval2018-T3-train-taskB.txt\",\n",
    "]\n",
    "\n",
    "EXPECTED_COLS = [\"Tweet Index\", \"Label\", \"Tweet text\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "05f769ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_semeval_file(path):\n",
    "    \"\"\"\n",
    "    读取单个 SemEval-2018 Task 3 文件（TSV）。\n",
    "    自动处理是否有表头。如果没有表头，赋予 EXPECTED_COLS。\n",
    "    \"\"\"\n",
    "    # 先读前几行判断是否有表头\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        head = [next(f).rstrip(\"\\n\") for _ in range(3)]\n",
    "    header_line = head[0]\n",
    "    has_header = all(col in header_line for col in [\"Tweet\", \"Label\"])  # 粗略判断\n",
    "\n",
    "    if has_header:\n",
    "        df = pd.read_csv(path, sep=\"\\t\", encoding=\"utf-8\")\n",
    "        # 兼容不同大小写/空格写法\n",
    "        colmap = {c: c.strip() for c in df.columns}\n",
    "        df.rename(columns=colmap, inplace=True)\n",
    "        # 尝试对齐列名\n",
    "        rename_guess = {}\n",
    "        for c in df.columns:\n",
    "            lc = c.lower().strip()\n",
    "            if \"tweet\" in lc and \"text\" in lc:\n",
    "                rename_guess[c] = \"Tweet text\"\n",
    "            elif lc.startswith(\"tweet\") and \"index\" in lc:\n",
    "                rename_guess[c] = \"Tweet Index\"\n",
    "            elif lc == \"label\":\n",
    "                rename_guess[c] = \"Label\"\n",
    "        if rename_guess:\n",
    "            df.rename(columns=rename_guess, inplace=True)\n",
    "    else:\n",
    "        # 无表头：直接按三列读\n",
    "        df = pd.read_csv(path, sep=\"\\t\", header=None, names=EXPECTED_COLS, encoding=\"utf-8\")\n",
    "\n",
    "    # 只保留需要的三列（防止多余列干扰）\n",
    "    for need in EXPECTED_COLS:\n",
    "        if need not in df.columns:\n",
    "            raise ValueError(f\"Missing expected column '{need}' in file: {path} (cols={list(df.columns)})\")\n",
    "    df = df[EXPECTED_COLS].copy()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4d0e4381",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) 读取并合并 taskA / taskB\n",
    "dfs = []\n",
    "for fn in FILES:\n",
    "    fp = os.path.join(IN_DIR, fn)\n",
    "    if not os.path.exists(fp):\n",
    "        raise FileNotFoundError(f\"Not found: {fp}\")\n",
    "    df_part = read_semeval_file(fp)\n",
    "    dfs.append(df_part)\n",
    "\n",
    "raw_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aec04f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) 规范化：去空白、丢弃空文本\n",
    "raw_df[\"Tweet text\"] = raw_df[\"Tweet text\"].astype(str).str.strip()\n",
    "raw_df.dropna(subset=[\"Tweet text\", \"Label\"], inplace=True)\n",
    "raw_df = raw_df[raw_df[\"Tweet text\"] != \"\"]\n",
    "\n",
    "# 3) 标签映射：0 -> non-sarcastic；其他 -> sarcastic\n",
    "def label_to_sarcasm(x):\n",
    "    try:\n",
    "        xi = int(x)\n",
    "    except Exception:\n",
    "        # 如果是字符串，尽力抽取数字\n",
    "        try:\n",
    "            xi = int(str(x).strip().split()[0])\n",
    "        except Exception:\n",
    "            raise ValueError(f\"Unrecognized label value: {x}\")\n",
    "    return 0 if xi == 0 else 1\n",
    "\n",
    "sarcasm = raw_df[\"Label\"].map(label_to_sarcasm).astype(int)\n",
    "sarcasm_name = sarcasm.map({0: \"non-sarcastic\", 1: \"sarcastic\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d00f320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) 生成目标 DataFrame\n",
    "out_df = pd.DataFrame({\n",
    "    \"text\": raw_df[\"Tweet text\"],\n",
    "    \"sarcasm\": sarcasm,\n",
    "    \"sarcasm_name\": sarcasm_name,\n",
    "    \"split\": \"train\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "18ebff6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split counts: {'train': 3821}\n",
      "Label counts: {'non-sarcastic': 1920, 'sarcastic': 1901}\n",
      "                                                   text  sarcasm  \\\n",
      "2755  Security Engineers are not Security Guards. :|...        1   \n",
      "1425  Taking a final then going straight to work. I'...        1   \n",
      "2186  @Katerintree obvi because every Jesuit is a he...        1   \n",
      "3497    This history essay is literally shitting on me.        0   \n",
      "3049  I refuse to be weak... #workout #motivation #f...        0   \n",
      "\n",
      "       sarcasm_name  split  \n",
      "2755      sarcastic  train  \n",
      "1425      sarcastic  train  \n",
      "2186      sarcastic  train  \n",
      "3497  non-sarcastic  train  \n",
      "3049  non-sarcastic  train  \n"
     ]
    }
   ],
   "source": [
    "# 5) 去重（可选）\n",
    "out_df.drop_duplicates(subset=[\"text\", \"sarcasm\"], inplace=True)\n",
    "\n",
    "# 6) 简要检查\n",
    "print(\"Split counts:\", out_df[\"split\"].value_counts().to_dict())\n",
    "print(\"Label counts:\", out_df[\"sarcasm_name\"].value_counts().to_dict())\n",
    "print(out_df.sample(5, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fc3f4d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>sarcasm_name</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sweet United Nations video. Just in time for C...</td>\n",
       "      <td>1</td>\n",
       "      <td>sarcastic</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@mrdahl87 We are rumored to have talked to Erv...</td>\n",
       "      <td>1</td>\n",
       "      <td>sarcastic</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey there! Nice to see you Minnesota/ND Winter...</td>\n",
       "      <td>1</td>\n",
       "      <td>sarcastic</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3 episodes left I'm dying over here</td>\n",
       "      <td>0</td>\n",
       "      <td>non-sarcastic</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I can't breathe! was chosen as the most notabl...</td>\n",
       "      <td>1</td>\n",
       "      <td>sarcastic</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sarcasm   sarcasm_name  \\\n",
       "0  Sweet United Nations video. Just in time for C...        1      sarcastic   \n",
       "1  @mrdahl87 We are rumored to have talked to Erv...        1      sarcastic   \n",
       "2  Hey there! Nice to see you Minnesota/ND Winter...        1      sarcastic   \n",
       "3                3 episodes left I'm dying over here        0  non-sarcastic   \n",
       "4  I can't breathe! was chosen as the most notabl...        1      sarcastic   \n",
       "\n",
       "   split  \n",
       "0  train  \n",
       "1  train  \n",
       "2  train  \n",
       "3  train  \n",
       "4  train  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7ee30a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/penglishao/Desktop/DS5500/project/data/processed/sarcasm_data/semeval2018_irony_train.csv\n"
     ]
    }
   ],
   "source": [
    "# 7) 保存\n",
    "csv_path = os.path.join(OUT_DIR, \"semeval2018_irony_train.csv\")\n",
    "out_df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Saved:\", csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f41a0a9",
   "metadata": {},
   "source": [
    "### iSarcasmEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8bd779cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"/Users/penglishao/Desktop/DS5500/project\"  # 改成你的项目根目录\n",
    "IN_DIR = os.path.join(BASE, \"data\", \"iSarcasmEval\")\n",
    "OUT_DIR = os.path.join(BASE, \"data\", \"processed\", \"sarcasm_data\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f8de0cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(s):\n",
    "    return (str(s) if pd.notna(s) else \"\").strip()\n",
    "\n",
    "def make_df(texts, labels, split):\n",
    "    df = pd.DataFrame({\n",
    "        \"text\": [clean_text(t) for t in texts],\n",
    "        \"sarcasm\": [int(x) for x in labels],\n",
    "        \"split\": split\n",
    "    })\n",
    "    df = df[df[\"text\"] != \"\"].copy()\n",
    "    df[\"sarcasm_name\"] = df[\"sarcasm\"].map({0: \"non-sarcastic\", 1: \"sarcastic\"})\n",
    "    return df[[\"text\", \"sarcasm\", \"sarcasm_name\", \"split\"]]\n",
    "\n",
    "all_parts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f2b484c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= 1) Train =========\n",
    "train_fp = os.path.join(IN_DIR, \"train.En.csv\")\n",
    "train = pd.read_csv(train_fp)\n",
    "\n",
    "# 期望字段: tweet, sarcastic, rephrase, 以及类别列（英）:\n",
    "# sarcasm, irony, satire, understatement, overstatement, rhetorical_question\n",
    "# a) 原tweet（带标签）\n",
    "train_tweets = make_df(train[\"tweet\"], train[\"sarcastic\"], split=\"train\")\n",
    "\n",
    "# b) rephrase -> 全部当作 non-sarcastic=0，单独作为新样本\n",
    "if \"rephrase\" in train.columns:\n",
    "    rephr = train[\"rephrase\"].fillna(\"\").astype(str)\n",
    "    # 只保留非空重述\n",
    "    mask = rephr.str.strip() != \"\"\n",
    "    train_rephr = make_df(rephr[mask], [0]*mask.sum(), split=\"train\")\n",
    "    all_parts += [train_tweets, train_rephr]\n",
    "else:\n",
    "    all_parts += [train_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c145bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ========= 2) Task A (test) =========\n",
    "# columns: text, sarcastic (0/1)\n",
    "taskA_fp = os.path.join(IN_DIR, \"task_A_En_test.csv\")\n",
    "if os.path.exists(taskA_fp):\n",
    "    taskA = pd.read_csv(taskA_fp)\n",
    "    # 有的版本列名可能是 'sarcastic' 或 'label'\n",
    "    labA = taskA[\"sarcastic\"] if \"sarcastic\" in taskA.columns else taskA[\"label\"]\n",
    "    partA = make_df(taskA[\"text\"], labA, split=\"test\")\n",
    "    all_parts.append(partA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c571fc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= 3) Task B (test) =========\n",
    "# columns example: text, sarcasm, irony, satire, understatement, overstatement, rhetorical_question\n",
    "# 若无 'sarcasm' 列，则可由多标签是否有任意一类=1 来近似推断讽刺（保险起见，这里优先用 'sarcasm' 列）\n",
    "taskB_fp = os.path.join(IN_DIR, \"task_B_En_test.csv\")\n",
    "if os.path.exists(taskB_fp):\n",
    "    taskB = pd.read_csv(taskB_fp)\n",
    "    if \"sarcasm\" in taskB.columns:\n",
    "        labB = taskB[\"sarcasm\"].astype(int)\n",
    "    else:\n",
    "        cat_cols = [c for c in [\"irony\",\"satire\",\"understatement\",\"overstatement\",\"rhetorical_question\"] if c in taskB.columns]\n",
    "        if not cat_cols:\n",
    "            raise ValueError(\"Task B file found but cannot infer sarcasm (no 'sarcasm' or category columns).\")\n",
    "        labB = (taskB[cat_cols].sum(axis=1) > 0).astype(int)\n",
    "    partB = make_df(taskB[\"text\"], labB, split=\"test\")\n",
    "    all_parts.append(partB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fd482a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ========= 4) Task C (test) =========\n",
    "# columns: text_0, text_1, sarcastic_id (0/1)\n",
    "# 需要把每行拆为两条样本：text_0 的讽刺标记 = (sarcastic_id==0)；text_1 的讽刺标记 = (sarcastic_id==1)\n",
    "taskC_fp = os.path.join(IN_DIR, \"task_C_En_test.csv\")\n",
    "if os.path.exists(taskC_fp):\n",
    "    taskC = pd.read_csv(taskC_fp)\n",
    "    # a) text_0\n",
    "    labC0 = (taskC[\"sarcastic_id\"].astype(int) == 0).astype(int)\n",
    "    partC0 = make_df(taskC[\"text_0\"], labC0, split=\"test\")\n",
    "    # b) text_1\n",
    "    labC1 = (taskC[\"sarcastic_id\"].astype(int) == 1).astype(int)\n",
    "    partC1 = make_df(taskC[\"text_1\"], labC1, split=\"test\")\n",
    "    all_parts += [partC0, partC1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c325012b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ========= 5) 合并、去重 =========\n",
    "sarcasm_df = pd.concat(all_parts, ignore_index=True)\n",
    "# 可按文本+标签去重（避免重复样本）\n",
    "sarcasm_df.drop_duplicates(subset=[\"text\", \"sarcasm\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5dfcacd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits: {'train': 4326, 'test': 1630}\n",
      "Labels: {'non-sarcastic': 4781, 'sarcastic': 1175}\n",
      "                                                   text  sarcasm  \\\n",
      "3589  I just fell down the stairs after holding the ...        0   \n",
      "5251  Woke up from a weird stress dream about our of...        0   \n",
      "4117  \"Screw the kid who brought a pineapple to home...        0   \n",
      "2310  Sorry I've not been that active in chat! I hav...        0   \n",
      "7484  Great start to a monday! Find your patience be...        1   \n",
      "\n",
      "       sarcasm_name  split  \n",
      "3589  non-sarcastic  train  \n",
      "5251  non-sarcastic   test  \n",
      "4117  non-sarcastic  train  \n",
      "2310  non-sarcastic  train  \n",
      "7484      sarcastic   test  \n"
     ]
    }
   ],
   "source": [
    "# ========= 6) 简要检查 =========\n",
    "print(\"Splits:\", sarcasm_df[\"split\"].value_counts().to_dict())\n",
    "print(\"Labels:\", sarcasm_df[\"sarcasm_name\"].value_counts().to_dict())\n",
    "print(sarcasm_df.sample(5, random_state=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3a2c5a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/penglishao/Desktop/DS5500/project/data/processed/sarcasm_data/isarcasmeval_merged.csv\n"
     ]
    }
   ],
   "source": [
    "# ========= 7) 保存 =========\n",
    "out_csv = os.path.join(OUT_DIR, \"isarcasmeval_merged.csv\")\n",
    "sarcasm_df.to_csv(out_csv, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Saved:\", out_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e6a9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
